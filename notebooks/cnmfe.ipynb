{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f25bdda-7790-454c-aafb-bbee6f9ab9cd",
   "metadata": {},
   "source": [
    "# Running this notebook\n",
    "\n",
    "**The visualizations in this notebook will run in [jupyter lab](https://github.com/jupyterlab/jupyterlab#installation), not jupyter notebook. Google colab is not supported either. VS Code notebooks _might_ work but that has not been tested.** See the fastplotlib supported frameworks for more info: https://github.com/fastplotlib/fastplotlib/#supported-frameworks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67669023-30e9-4661-931c-4ab2c554ff12",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tifffile\n",
    "from ipywidgets import IntSlider, VBox\n",
    "import fastplotlib as fpl\n",
    "\n",
    "from caiman.motion_correction import high_pass_filter_space\n",
    "from caiman.summary_images import correlation_pnr\n",
    "\n",
    "import mesmerize_core as mc\n",
    "from mesmerize_core.arrays import LazyTiff\n",
    "from mesmerize_viz import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1fb091-b86c-45c3-a59d-995a7ef28cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mesmerize_core.caiman_extensions.cnmf import cnmf_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e174dd7d-a1ed-43ec-a0c0-cda1e1ee81b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.name == \"nt\":\n",
    "    # disable the cache on windows, this will be automatic in a future version\n",
    "    cnmf_cache.set_maxsize(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff12d10-980d-454a-a023-e593243a0709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mac users!\n",
    "# temporary patch for Mac, won't be necessary in next release\n",
    "# Thanks Ryan Ly for the PR! :D I need to dig into it more before merging\n",
    "# conda_prefix_1_str = os.environ['CONDA_PREFIX'].replace(os.path.join(' ', 'envs', 'mescore')[1:], '')\n",
    "# os.environ['CONDA_PREFIX_1'] = conda_prefix_1_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6412b39-20ff-46cb-972e-52e8dcc1eb00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is just a pandas table display formatting option\n",
    "pd.options.display.max_colwidth = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cda36a4-704d-4762-a3c4-0e717ebc1f4d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Paths\n",
    "\n",
    "`mesmerize-core` helps manage the outputs of caiman algorithms and organizes \"parameter variants\" - the output of a given combination of input data and algorithm parameters. In order to run the algorithms you must tell `mesmerize-core` where your _input data_ are located and decide on a **top level raw data directory**. For example consider the following directory structure of experimental data (you may organize your raw data however you wish, this is just an example). We can see that all the experimental data lies under `/data/group_name/my_name/exp_data`. Therefore we can use this `exp_data` dir as a `parent raw data path`. `mesmerize-core` will then only store the _relative_ paths to the raw data files, this allows you to move datasets between computers and filesystems. `mesmerize-core` does not store any hard file paths, only relative paths.\n",
    "\n",
    "```\n",
    "/data/group_name/my_name\n",
    "                        └── exp_data\n",
    "                            ├── axonal_imaging\n",
    "                            │   ├── mouse_1\n",
    "                            │   │   ├── exp_a.tiff\n",
    "                            │   │   ├── exp_b.tiff\n",
    "                            │   │   └── exp_c.tiff\n",
    "                            │   ├── mouse_2\n",
    "                            │   │   ├── exp_a.tiff\n",
    "                            │   │   └── exp_b.tiff\n",
    "                            │   └── mouse_3\n",
    "                            └── hippocampus_imaging\n",
    "                                ├── mouse_1\n",
    "                                │   ├── exp_a.tiff\n",
    "                                │   ├── exp_b.tiff\n",
    "                                │   └── exp_c.tiff\n",
    "                                ├── mouse_2\n",
    "                                └── mouse_3\n",
    "```\n",
    "\n",
    "**For this demo set the `caiman_data` dir as the parent raw data path**\n",
    "\n",
    "Sidenote: We recommend using [pathlib](https://docs.python.org/3/library/pathlib.html) instead of manually managing paths as strings. `pathlib` is just a part of the Python standard library, it makes it much easier to deal with paths and saves a lot of time in the long-run! It also makes your paths compatible across operating systems. Therefore even if you are on Windows you can use the regular `/` for paths, you do not have to worry about the strangeness of `\\\\` and `\\`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef02320-6407-4d29-833c-33e9bcd00703",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for this demo set this dir as the path to your `caiman_data` dir\n",
    "mc.set_parent_raw_data_path(\"/home/kushal/caiman_data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91abab59-07a1-4716-9935-0e1840619930",
   "metadata": {},
   "source": [
    "### Batch path, this is where caiman outputs will be organized\n",
    "\n",
    "This can be anywhere, it does not need to be under the parent raw data path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e356e0e-36f7-45d3-86b6-1a25a8287f13",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_path = mc.get_parent_raw_data_path().joinpath(\"mesmerize-cnmfe/batch.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986a89a9-7245-4fe2-a2dc-2c1e97d5488a",
   "metadata": {},
   "source": [
    "# Create a new batch\n",
    "\n",
    "This creates a new pandas `DataFrame` with the columns that are necessary for mesmerize. In mesmerize we call this the **batch DataFrame**. You can add additional columns relevant to your experiment, but do not modify columns used by mesmerize.\n",
    "\n",
    "Note that when you create a DataFrame you will need to use `load_batch()` to load it later. You cannot use `create_batch()` to overwrite an existing batch DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f0faca-e5a4-4f84-8290-9e48b8f88631",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a new batch\n",
    "df = mc.create_batch(batch_path)\n",
    "# to load existing batches use `load_batch()`\n",
    "# df = load_batch(batch_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f117bc14-b228-4427-84a9-8dd915837fc4",
   "metadata": {},
   "source": [
    "# View the dataframe\n",
    "\n",
    "It is empty and has the required columns for mesmerize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263e6e3a-51ac-4edc-ad63-29bad143684e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fb134e-2e2b-4ed1-8be9-ab0deb82c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use the data_endoscope movie from caiman\n",
    "# download it if you don't have it\n",
    "from caiman.utils.utils import download_demo\n",
    "download_demo(\"data_endoscope.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d9d814-7bde-431e-8c98-abcd6aa231cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movie_path = mc.get_parent_raw_data_path().joinpath(\"example_movies/data_endoscope.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2996e126-8f11-449b-86b3-85bbc9ff03d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# gSig_filt\n",
    "\n",
    "A high-pass spatial filter is useful for motion correction of miniscope 1p data, or other data which has large amounts of low frequency background flutuations.\n",
    "\n",
    "The `gSig_filt` param sets the `sigma` of the gaussian kernel used for filtering. We can use fastplotlib to visualize the effects of this parameter. We want to remove the low frequency spatial information from the image to create better template images for motion correction.\n",
    "\n",
    "Note that this is different from the `gSig` parameter used in CNMF!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5d9f48-c1c6-4366-bc5a-2137691df44f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get out input movie\n",
    "# if it is memmapable you can use tifffile.memmap\n",
    "# for other formats you can try LazyTiff, or any suitable lazy loader\n",
    "input_movie = tifffile.imread(movie_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7646bd-f3e2-4058-9d67-ac43ba43c020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a slider for gSig_filt\n",
    "slider_gsig_filt = IntSlider(value=3, min=1, max=33, step=2,  description=\"gSig_filt\")\n",
    "\n",
    "def apply_filter(frame):\n",
    "    # read slider value\n",
    "    gSig_filt = (slider_gsig_filt.value, slider_gsig_filt.value)\n",
    "    \n",
    "    # apply filter\n",
    "    return high_pass_filter_space(frame, gSig_filt)\n",
    "\n",
    "# we can use frame_apply feature of `ImageWidget` to apply \n",
    "# the filter before displaying frames\n",
    "funcs = {\n",
    "    # data_index: function\n",
    "    1: apply_filter  # filter shown on right plot, index 1\n",
    "}\n",
    "\n",
    "# input movie will be shown on left, filtered on right\n",
    "iw_gs = fpl.ImageWidget(\n",
    "    data=[input_movie, input_movie.copy()],\n",
    "    frame_apply=funcs,\n",
    "    names=[\"raw\", \"filtered\"],\n",
    "    grid_plot_kwargs={\"size\": (1200, 600)},\n",
    "    cmap=\"gnuplot2\"\n",
    ")\n",
    "\n",
    "def force_update(*args):\n",
    "    # kinda hacky but forces the images to update \n",
    "    # when the gSig_filt slider is moved\n",
    "    iw_gs.current_index = iw_gs.current_index\n",
    "    iw_gs.reset_vmin_vmax()\n",
    "\n",
    "iw_gs.reset_vmin_vmax()\n",
    "    \n",
    "slider_gsig_filt.observe(force_update, \"value\")\n",
    "\n",
    "VBox([iw_gs.show(), slider_gsig_filt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511192a7-6e25-49cf-8175-0ecfb0001662",
   "metadata": {},
   "source": [
    "# reset vmin vmax when necessary!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbca4882-7d04-41fa-adbb-74c1a8eb4b13",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Motion correction parameters\n",
    "\n",
    "Parameters for all algos have the following structure:\n",
    "\n",
    "```python\n",
    "{\"main\": {... params directly passed to caiman}}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf4a68d-e97f-4738-bdec-29905590af60",
   "metadata": {},
   "outputs": [],
   "source": [
    "params =\\\n",
    "{\n",
    "    \"main\":\n",
    "    {\n",
    "        \"gSig_filt\": (3, 3), # a gSig_filt value that brings out \"landmarks\" in the movie\n",
    "        \"pw_rigid\": True,\n",
    "        \"max_shifts\": (5, 5),\n",
    "        \"strides\": (48, 48),\n",
    "        \"overlaps\": (24, 24),\n",
    "        \"max_deviation_rigid\": 3,\n",
    "        \"border_nan\": \"copy\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cecd0f-334d-4bc1-ab85-752a25d5518b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Add a \"batch item\", this is the combination of:\n",
    "* algorithm to run, `algo`\n",
    "* input movie to run the algorithm on, `input_movie_path`\n",
    "* parameters for the specified algorithm, `params`\n",
    "* a name for you to keep track of things, usually the same as the movie filename, `item_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7156e8-0868-4de9-af6a-b3f4959ade3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.caiman.add_item(\n",
    "    algo=\"mcorr\",\n",
    "    input_movie_path=movie_path,\n",
    "    params=params,\n",
    "    item_name=movie_path.stem\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc2afb2-d282-4227-8bdd-fbd498dc5144",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "We can now see that there is one item, a.k.a. row or pandas `Series`, in the batch dataframe, we can add another item with the same input movie but with different parameters.\n",
    "\n",
    "**When adding batch items with the same `input_movie_path` (i.e. same input movie but different parameters) it is useful to give them the same `item_name`.**\n",
    "\n",
    "Let's try one more with different `gSig_filt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc683ee4-1d4d-4407-953a-82a215740fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params2 =\\\n",
    "{\n",
    "    \"main\":\n",
    "    {\n",
    "        \"gSig_filt\": (1, 1), # a gSig_filt value that brings out \"landmarks\" in the movie\n",
    "        \"pw_rigid\": True,\n",
    "        \"max_shifts\": (5, 5),\n",
    "        \"strides\": (48, 48),\n",
    "        \"overlaps\": (24, 24),\n",
    "        \"max_deviation_rigid\": 3,\n",
    "        \"border_nan\": \"copy\",\n",
    "    }\n",
    "}\n",
    "\n",
    "df.caiman.add_item(\n",
    "    algo=\"mcorr\",\n",
    "    input_movie_path=movie_path,\n",
    "    params=params2,\n",
    "    item_name=movie_path.stem\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9012a748-79d5-4e4a-887f-cc8f26b86cc6",
   "metadata": {},
   "source": [
    "# We can see that there are two batch items for the same input movie.\n",
    "\n",
    "Use a `for` loop to add multiple different parameter variants more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b758dfd-c7af-4e9f-879e-7b3e9456dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the mcorr_params2 dict to make some changes\n",
    "new_params = deepcopy(params)\n",
    "\n",
    "# some variants of max_shifts\n",
    "# but this can be any params\n",
    "for shifts in [1, 3, 10]: \n",
    "    # deep copy is the safest way to copy dicts\n",
    "    new_params = deepcopy(new_params)\n",
    "    \n",
    "    # assign the \"max_shifts\"\n",
    "    new_params[\"main\"][\"max_shifts\"] = (shifts, shifts)\n",
    "    \n",
    "    df.caiman.add_item(\n",
    "      algo='mcorr',\n",
    "      item_name=movie_path.stem,\n",
    "      input_movie_path=movie_path,\n",
    "      params=new_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1ffb38-4107-46bc-9a74-e3bdfcae2d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b37050-9065-4b1f-96fb-753f6f33fc65",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can use the `caiman.get_params_diffs()` extension to see the unique parameters between rows with the same `item_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd5b4e1-c8fc-40e0-9a77-a0e3403ce120",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = df.caiman.get_params_diffs(algo=\"mcorr\", item_name=df.iloc[0][\"item_name\"])\n",
    "diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd8cdde-6a83-4d63-808a-1a05628893ea",
   "metadata": {},
   "source": [
    "# Run an item\n",
    "\n",
    "There is only one item in this DataFrame and it is located at index `0`. You can run a row using `df.iloc[index].caiman.run()`\n",
    "\n",
    "Technical notes: On Linux & Mac it will run in subprocess but on Windows it will run in the local kernel. If using the subprocess backend (only Linux & Mac) you can use `run(wait=False)` if you don't want to block the kernel while running. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a0d36b-ec96-410a-94f3-fafdea28d08c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[0].caiman.run()\n",
    "\n",
    "# reload dataframe from disk when done\n",
    "df = df.caiman.reload_from_disk()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f003d-2e34-42f5-9fc4-526c025b550c",
   "metadata": {},
   "source": [
    "# Run multiple batch items.\n",
    "\n",
    "`df.iterrows()` iterates through rows and returns the numerical index and row for each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb02c6d2-b302-487b-bcf6-81e8dc47006c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():\n",
    "    if row[\"outputs\"] is not None: # item has already been run\n",
    "        continue # skip\n",
    "        \n",
    "    process = row.caiman.run()\n",
    "    \n",
    "    # on Windows you MUST reload the batch dataframe after every iteration because it uses the `local` backend.\n",
    "    # this is unnecessary on Linux & Mac\n",
    "    # \"DummyProcess\" is used for local backend so this is automatic\n",
    "    if process.__class__.__name__ == \"DummyProcess\":\n",
    "        df = df.caiman.reload_from_disk()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4c526a-777f-4769-8aa9-5e3b0459e908",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Reload the DataFrame\n",
    "\n",
    "It is necessary to use `df = df.caiman.reload_from_disk()` after running a single batch item or a loop of batch items. You must not add new batch items until you reload it if you have ran items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbe5f0f-84a0-4e87-9c3e-8d922c7cfd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.caiman.reload_from_disk()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895120e6-49b5-4f78-99ec-7c294d640604",
   "metadata": {},
   "source": [
    "## We can see that the `outputs` column has been filled in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc3d5a-7eec-490b-b53e-26aadc086559",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5885441e-a049-4412-9306-fb716751d6dc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Visualize results\n",
    "\n",
    "We will use the high pass spatial filter to make it easier to perform visual quality control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18098d5e-d560-4a49-a400-63efff86d7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = LazyTiff(df.iloc[0].caiman.get_input_movie_path())\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b474cdd-6dcd-4cc5-98c4-50c99d23777b",
   "metadata": {},
   "source": [
    "**This tiff file doesn't work with `tiffile.memmap` and `LazyTiff` is unable to guess its shape. So we will use `LazyTiff` with a forced shape**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8acc70-2fdc-4bd7-a015-d252f78edef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weird_movie(path):\n",
    "    return LazyTiff(path, shape=(1000, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a1616b-e66e-470e-8413-a498ab8be82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# high pass filter the data to see shifts more easily\n",
    "filt = lambda x: high_pass_filter_space(x, (3, 3))\n",
    "\n",
    "funcs = {\n",
    "    0: filt,\n",
    "    1: filt\n",
    "}\n",
    "\n",
    "viz_mcor = df.mcorr.viz(\n",
    "    input_movie_kwargs={\"reader\": load_weird_movie},\n",
    "    image_widget_kwargs={\"frame_apply\": funcs}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07414f76-5183-4e16-b05f-b2d81ba82084",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_mcor.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72edc75-2a35-4a85-a9f5-c6ade16d5569",
   "metadata": {},
   "source": [
    "# Customize the visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f48ce6d-6dea-41dd-8d08-cd1317012df3",
   "metadata": {},
   "source": [
    "disable the spatial filter. Reset vmin vmax after removing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333f29c6-ecf4-4d67-9a2c-12e184c80747",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_mcor.image_widget.frame_apply = dict()  # empty dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1193b3de-e8b1-4239-b036-46812602d017",
   "metadata": {},
   "source": [
    "Use the spatial filter again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102e923e-df4b-48f9-862b-63ef7a561bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_mcor.image_widget.frame_apply = funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad69731-e057-4ad7-acf7-dd61269ecd72",
   "metadata": {},
   "source": [
    "# Optional, cleanup\n",
    "\n",
    "All the movies here look pretty good so I'll continue with `index = 0`. You can cleanup the DataFrame and remove all other items.\n",
    "\n",
    "Remove batch items (i.e. rows) using `df.caiman.remove_item(<item_uuid>)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b420e485-4f70-41c1-ae68-97c8c0f502b4",
   "metadata": {},
   "source": [
    "**Note:** On windows calling `remove_item()` will raise a `PermissionError` if you have the memmap file open. The workaround is to shutdown the current kernel and then use `df.caiman.remove_item()`. For example, you can keep another notebook that you use just for cleaning unwanted mcorr items.\n",
    "\n",
    "There is currently no way to close a `numpy.memmap`: https://github.com/numpy/numpy/issues/13510"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6177e29e-c6af-4ead-8925-bad600e797b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of rows we want to keep using the uuids\n",
    "rows_keep = [df.iloc[3].uuid]\n",
    "rows_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e661d4e-989b-4478-9aeb-42520fd78531",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():\n",
    "    if row.uuid not in rows_keep:\n",
    "        df.caiman.remove_item(row.uuid)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c80220c-73ce-40c8-83b5-add404b805ad",
   "metadata": {},
   "source": [
    "# CNMF\n",
    "## corr-pnr seeding\n",
    "\n",
    "This visualization is to help determine values for `min_corr` (correlation) and `min_pnr` (peak to noise ratio) for seeding CNMFE. Pixels below these thresholds will be excluded from the results.\n",
    "\n",
    "If `correlation_pnr` takes a long time you can increase the subsample to make it larger than `2`. Example: `mcorr_movie[::5]`\n",
    "\n",
    "You should try different values of `gSig`, this is different from `gSig_filt`. You will use this gSig as a CNMFE param as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02472f11-ec6c-4c02-9c6e-38620f65773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the motion corrected output, this is a memmap array\n",
    "mcorr_movie = df.iloc[0].mcorr.get_output()\n",
    "\n",
    "gSig = 3\n",
    "corr, pnr = correlation_pnr(mcorr_movie[::2], gSig=gSig, swap_dim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b657a1-25cf-422b-a18c-202d4d9eb72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to show the correlation and pnr images\n",
    "iw_corr_pnr = fpl.ImageWidget(\n",
    "    [corr, pnr], \n",
    "    names=[\"corr\", \"pnr\"],\n",
    "    grid_plot_kwargs={\"size\": (650, 300)},\n",
    "    cmap=\"turbo\",\n",
    ")\n",
    "\n",
    "# mcorr vids, we will display thresholded mcorr vids\n",
    "mcorr_vids = [mcorr_movie.astype(np.float32) for i in range(4)]\n",
    "\n",
    "# sync the threshold image widget with the corr-pnr plot\n",
    "threshold_grid_plot_kwargs = {\n",
    "    \"controllers\": [[iw_corr_pnr.gridplot[\"corr\"].controller]*2]*2,\n",
    "    \"size\": (650, 600)\n",
    "}\n",
    "\n",
    "iw_thres_movie = fpl.ImageWidget(\n",
    "    mcorr_vids, \n",
    "    names=[\"over corr threshold\", \"over pnr threshold\", \"under corr threshold\", \"under pnr threshold\"],\n",
    "    # sync this with the corr-pnr plot\n",
    "    grid_plot_kwargs=threshold_grid_plot_kwargs,\n",
    "    cmap=\"gnuplot2\"\n",
    ")\n",
    "\n",
    "# display threshold of the spatially filtered movie\n",
    "def spatial_filter(frame):\n",
    "    f = high_pass_filter_space(frame, (3, 3))\n",
    "    return f\n",
    "\n",
    "\n",
    "# threshold\n",
    "def threshold(frame, mask):\n",
    "    # optionally use spatial filter\n",
    "    t = spatial_filter(frame)\n",
    "    \n",
    "    t = t.copy()\n",
    "    \n",
    "    t[mask] = t.min()\n",
    "    \n",
    "    return t\n",
    "\n",
    "# Set the thresholded images using the vmin set from top subplots\n",
    "# dict of threshold lambda wrappers to set on ImageWidget\n",
    "# this sets the frame_apply for each subplot\n",
    "threshold_funcs = {\n",
    "    0: lambda frame: threshold(frame, corr < iw_corr_pnr.gridplot[\"corr\"].graphics[0].cmap.vmin),\n",
    "    1: lambda frame: threshold(frame, pnr < iw_corr_pnr.gridplot[\"pnr\"].graphics[0].cmap.vmin),\n",
    "    2: lambda frame: threshold(frame, corr > iw_corr_pnr.gridplot[\"corr\"].graphics[0].cmap.vmin),\n",
    "    3: lambda frame: threshold(frame, pnr > iw_corr_pnr.gridplot[\"pnr\"].graphics[0].cmap.vmin)\n",
    "}\n",
    "\n",
    "# set the dict of lambda wrappers\n",
    "iw_thres_movie.frame_apply = threshold_funcs\n",
    "\n",
    "# update threshold plots when the corr pnr sliders move\n",
    "def update_threshold_plots(*args):\n",
    "    iw_thres_movie.current_index = iw_thres_movie.current_index\n",
    "\n",
    "# this will get easier in the future\n",
    "iw_corr_pnr.gridplot[\"corr\"].docks[\"right\"][\"histogram_lut\"].linear_region.selection.add_event_handler(update_threshold_plots)\n",
    "iw_corr_pnr.gridplot[\"pnr\"].docks[\"right\"][\"histogram_lut\"].linear_region.selection.add_event_handler(update_threshold_plots)\n",
    "\n",
    "VBox([iw_corr_pnr.show(), iw_thres_movie.show()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851a1982-5503-4327-acd2-50ced4f80f2a",
   "metadata": {},
   "source": [
    "# reset vmin vmax when necessary!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66b40c7-72f6-40d2-97e4-29811d31e532",
   "metadata": {},
   "source": [
    "# corr and pnr values from the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3421b7c-b838-4435-b6f4-b8d9559eb5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_pnr = {\n",
    "    'min_corr': iw_corr_pnr.gridplot[\"corr\"].graphics[0].cmap.vmin, # corr value from previous plot\n",
    "    'min_pnr': iw_corr_pnr.gridplot[\"pnr\"].graphics[0].cmap.vmin,  # PNR value from previous plot\n",
    "}\n",
    "corr_pnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257a7c96-c5ce-4f66-9a91-33c26fa8b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_cnmfe =\\\n",
    "{\n",
    "    \"main\":\n",
    "    {\n",
    "        'method_init': 'corr_pnr',  # use this for 1 photon\n",
    "        'K': None,\n",
    "        'gSig': (gSig, gSig),\n",
    "        'gSiz': (4 * gSig + 1, 4 * gSig + 1),\n",
    "        'merge_thr': 0.7,\n",
    "        'p': 1,\n",
    "        'tsub': 2,\n",
    "        'ssub': 1,\n",
    "        'rf': 40,\n",
    "        'stride': 20,\n",
    "        'only_init': True,    # set it to True to run CNMF-E\n",
    "        'nb': 0,\n",
    "        'nb_patch': 0,\n",
    "        'method_deconvolution': 'oasis',       # could use 'cvxpy' alternatively\n",
    "        'low_rank_background': None,\n",
    "        'update_background_components': True,  # sometimes setting to False improve the results\n",
    "        'normalize_init': False,               # just leave as is\n",
    "        'center_psf': True,                    # leave as is for 1 photon\n",
    "        'ssub_B': 2,\n",
    "        'ring_size_factor': 1.4,\n",
    "        'del_duplicates': True,                # whether to remove duplicates from initialization\n",
    "        **corr_pnr # unpack corr_pnr vals into here\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe711552-fb1c-4f3d-8098-6967a1ca46cf",
   "metadata": {},
   "source": [
    "# Add a single cnmf item to the batch\n",
    "\n",
    "When you use `algo=\"cnmfe\"`, it basically forces the following parameters:\n",
    "```python\n",
    "\"method_init\": \"corr_pnr\",\n",
    "\"n_processes\": n_processes,\n",
    "\"only_init\": True,  # for 1p\n",
    "\"center_psf\": True,  # for 1p\n",
    "\"normalize_init\": False,  # for 1p\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736afb50-7090-4433-bbb8-28b924da57d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.caiman.add_item(\n",
    "    algo=\"cnmfe\",\n",
    "    input_movie_path=df.iloc[0],\n",
    "    params=params_cnmfe,\n",
    "    item_name=df.iloc[0][\"item_name\"]\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102e295a-5543-4ad3-aaa5-fb76e819950a",
   "metadata": {},
   "source": [
    "# Parameter search\n",
    "\n",
    "Just like with motion correction, we can use loops to add multiple parameter variants. This is useful to perform a parameter search to find the params that work best for your dataset. Here I will use `itertools.product` which is better than deeply nested loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9910214-ca37-47c2-b309-76623113616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "# variants of several parameters\n",
    "# you can make lists for as many params as you want\n",
    "K_variants = [None, 10]\n",
    "merge_thr_variants = [0.6, 0.8, 0.9, 0.98]\n",
    "\n",
    "# always use deepcopy like before\n",
    "new_params_cnmf = deepcopy(params_cnmfe)\n",
    "\n",
    "# create a parameter grid\n",
    "# product is a nice way to create all combinations of multiple iterables like lists\n",
    "parameter_grid = product(K_variants, merge_thr_variants)\n",
    "\n",
    "# a single for loop to go through all the various parameter combinations\n",
    "for K, merge_thr in parameter_grid:\n",
    "    # deep copy params dict just like before\n",
    "    new_params_cnmf = deepcopy(new_params_cnmf)\n",
    "    \n",
    "    # one set of parameter combinations\n",
    "    new_params_cnmf[\"main\"][\"K\"] = K\n",
    "    new_params_cnmf[\"main\"][\"merge_thr\"] = merge_thr\n",
    "    \n",
    "    # add param combination variant to batch\n",
    "    df.caiman.add_item(\n",
    "        algo=\"cnmfe\",\n",
    "        item_name=df.iloc[0][\"item_name\"],\n",
    "        input_movie_path=df.iloc[0],\n",
    "        params=new_params_cnmf\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162090e3-5298-4843-a4cb-108d3ad19631",
   "metadata": {},
   "source": [
    "See that there are a lot of new cnmf batch items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93531399-5b80-4c76-ae28-c8156a84a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca2e87c-76ce-4fa3-93b4-146aad957aa9",
   "metadata": {},
   "source": [
    "# Param diffs\n",
    "\n",
    "The index numbers on the diffs correspond to the indices in the parent DataFrame above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737f0066-ea1e-4974-8fb2-9186618c9e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.caiman.get_params_diffs(algo=\"cnmfe\", item_name=df.iloc[1][\"item_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e26265c-5cb7-461f-8e89-5744e2f5e82d",
   "metadata": {},
   "source": [
    "# Run items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5694187a-48e9-4769-82d3-afd46dd19a00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():\n",
    "    if row[\"outputs\"] is not None: # item has already been run\n",
    "        continue # skip\n",
    "        \n",
    "    process = row.caiman.run()\n",
    "    \n",
    "    # on Windows you MUST reload the batch dataframe after every iteration because it uses the `local` backend.\n",
    "    # this is unnecessary on Linux & Mac\n",
    "    # \"DummyProcess\" is used for local backend so this is automatic\n",
    "    if process.__class__.__name__ == \"DummyProcess\":\n",
    "        df = df.caiman.reload_from_disk()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c339a43e-a8bc-4f04-abb7-a31e226f7803",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# We now have CNMFE outputs :D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb66e97-513a-4012-861a-61ac77d9f4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.caiman.reload_from_disk()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5be63f-bc9b-4eb1-a8d7-96e228fbd536",
   "metadata": {},
   "source": [
    "# Visualize using `mesmerize-viz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800ec0ae-d636-490d-9f3d-2d18cef3f671",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mesmerize_viz import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2769136c-a5a8-467e-8e9b-df1170eccdb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "viz = df.cnmf.viz(\n",
    "    image_data_options=[\"input\", \"rcm\"], # cnmfe does not support rcb and residuals yet\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac86a23-1431-4848-8ee9-4d91664a99b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "viz.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d36df25-2c1b-498b-9250-91b49fc3466a",
   "metadata": {},
   "source": [
    "# This seemingly complex visualization is still customizable!\n",
    "\n",
    "Public attributes:\n",
    "\n",
    "- `image_widget`: the `ImageWidget` in the visualization\n",
    "- `plot_temporal`: the temporal `Plot`\n",
    "- `plot_heatmap`: the heatmap `Plot`\n",
    "- `cnmf_obj`: The cnmf object currently being visualized. This object gets saved to disk when you click the \"Save Eval to disk\" button.\n",
    "- `component_index`: current component index, `int`\n",
    "\n",
    "A few public methods:\n",
    "- `show()` show the visualization\n",
    "- `set_component_index(index: int)` manually set the component index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6566628e-1f56-4812-9fe9-f4d0ebd68ddc",
   "metadata": {},
   "source": [
    "# Set frame_apply functions to the image widget. Reset the vmin-vmax as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419753af-096f-43ed-8716-56546f73ecbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "viz.image_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d357462f-d35f-4bea-933d-c7b6123959d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "funcs = {\n",
    "    0: lambda frame: high_pass_filter_space(frame, (3, 3))\n",
    "}\n",
    "\n",
    "viz.image_widget.frame_apply = funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8190092a-50d0-4093-9dcc-61122580bdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.image_widget.cmap = \"gray\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86a0ef4-3de3-4d4a-b9d1-279796ae9fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
